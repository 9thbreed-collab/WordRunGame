# Plan 04-03: Content Pipeline + Baseline Content

**Phase:** 04-obstacles-boosts-content
**Scope:** ContentCache autoload, WordValidator, ProfanityFilter, JSON content format, baseline bundled content, LevelData builder
**Requirements:** CONT-01 through CONT-07

---

## Context

The content pipeline separates word-pair data from the game binary. Cloud delivery comes in Phase 7 (backend), but this plan builds the local side: JSON content format, local cache, validation, profanity filtering, and baseline bundled content. The game loads levels from JSON instead of hardcoded .tres files, enabling future OTA updates.

### Design Decisions

- **JSON over .tres for content**: Level content uses JSON for cloud compatibility. `.tres` resources are still used for configs (SurgeConfig, ObstacleConfig) since those are engine-side.
- **Baseline bundled content**: Ship with `res://data/baseline/` JSON files so the game works offline without any cloud fetch. Cloud content updates override these when available (Phase 7).
- **Validation runs at build time, not runtime**: WordValidator and ProfanityFilter are editor/build tools, not runtime systems. We validate content before bundling -- the game trusts bundled content is clean.
- **Land theming**: Each land gets its own JSON file with themed word pairs and difficulty ratings.
- **Scope for this plan**: 1 test land with 10 levels (not the full 250 -- that's content authoring work outside the codebase).

---

## Tasks

### Task 1: Define JSON content schema

**File:** `data/baseline/schema.json` (NEW -- reference only, not loaded by game)

```json
{
  "land_id": "grasslands",
  "display_name": "Grasslands",
  "theme": "nature, animals, plants",
  "levels": [
    {
      "level_id": "grasslands_01",
      "level_name": "Level 1",
      "time_limit_seconds": 180,
      "difficulty": 1,
      "word_pairs": [
        { "word_a": "", "word_b": "grass" },
        { "word_a": "grass", "word_b": "hopper" }
      ],
      "surge_config": {
        "max_value": 100.0,
        "fill_per_word": 15.0,
        "thresholds": [30.0, 60.0, 80.0],
        "section_drain_times": [15.3, 9.35, 5.95, 4.25],
        "bust_drain_rate": 25.0,
        "multipliers": [1.0, 1.5, 2.0, 3.0]
      },
      "obstacle_configs": [
        {
          "obstacle_type": "padlock",
          "word_index": 5,
          "trigger_type": "word_start",
          "delay_seconds": 0.0,
          "effect_data": {}
        }
      ]
    }
  ]
}
```

### Task 2: Create ContentCache autoload

**File:** `scripts/autoloads/content_cache.gd` (NEW)

ContentCache manages loading and caching level content:

```gdscript
class_name ContentCache
extends Node

const BASELINE_DIR = "res://data/baseline/"
const CACHE_DIR = "user://content_cache/"

var _land_cache: Dictionary = {}  # land_id -> parsed JSON data

func _ready() -> void:
    _ensure_cache_dir()

func _ensure_cache_dir() -> void:
    if not DirAccess.dir_exists_absolute(CACHE_DIR):
        DirAccess.make_dir_recursive_absolute(CACHE_DIR)

## Load a land's content. Checks user cache first, falls back to baseline.
func load_land(land_id: String) -> Dictionary:
    if _land_cache.has(land_id):
        return _land_cache[land_id]

    var data := _try_load_json(CACHE_DIR + land_id + ".json")
    if data.is_empty():
        data = _try_load_json(BASELINE_DIR + land_id + ".json")

    if not data.is_empty():
        _land_cache[land_id] = data
    return data

## Build a LevelData resource from JSON level entry
func build_level_data(level_json: Dictionary) -> LevelData:
    var level := LevelData.new()
    level.level_name = level_json.get("level_name", "")
    level.time_limit_seconds = level_json.get("time_limit_seconds", 180)

    # Build word pairs
    var pairs_json: Array = level_json.get("word_pairs", [])
    for pair_data in pairs_json:
        var wp := WordPair.new()
        wp.word_a = pair_data.get("word_a", "")
        wp.word_b = pair_data.get("word_b", "")
        level.word_pairs.append(wp)

    # Build surge config
    var surge_json: Dictionary = level_json.get("surge_config", {})
    if not surge_json.is_empty():
        var sc := SurgeConfig.new()
        sc.max_value = surge_json.get("max_value", 100.0)
        sc.fill_per_word = surge_json.get("fill_per_word", 15.0)
        sc.thresholds = Array(surge_json.get("thresholds", [30.0, 60.0, 80.0]), TYPE_FLOAT, "", null)
        sc.section_drain_times = Array(surge_json.get("section_drain_times", [15.3, 9.35, 5.95, 4.25]), TYPE_FLOAT, "", null)
        sc.bust_drain_rate = surge_json.get("bust_drain_rate", 25.0)
        sc.multipliers = Array(surge_json.get("multipliers", [1.0, 1.5, 2.0, 3.0]), TYPE_FLOAT, "", null)
        level.surge_config = sc

    # Build obstacle configs
    var obstacles_json: Array = level_json.get("obstacle_configs", [])
    for obs_data in obstacles_json:
        var oc := ObstacleConfig.new()
        oc.obstacle_type = obs_data.get("obstacle_type", "")
        oc.display_name = obs_data.get("display_name", oc.obstacle_type)
        oc.word_index = obs_data.get("word_index", 0)
        oc.trigger_type = obs_data.get("trigger_type", "word_start")
        oc.delay_seconds = obs_data.get("delay_seconds", 0.0)
        oc.effect_data = obs_data.get("effect_data", {})
        level.obstacle_configs.append(oc)

    return level

## Get level count for a land
func get_level_count(land_id: String) -> int:
    var data := load_land(land_id)
    return data.get("levels", []).size()

## Get specific level JSON from a land
func get_level_json(land_id: String, level_index: int) -> Dictionary:
    var data := load_land(land_id)
    var levels: Array = data.get("levels", [])
    if level_index < levels.size():
        return levels[level_index]
    return {}

func _try_load_json(path: String) -> Dictionary:
    if not FileAccess.file_exists(path):
        return {}
    var file := FileAccess.open(path, FileAccess.READ)
    if file == null:
        return {}
    var text := file.get_as_text()
    file.close()
    var json := JSON.new()
    var err := json.parse(text)
    if err != OK:
        push_warning("ContentCache: Failed to parse JSON at " + path)
        return {}
    if json.data is Dictionary:
        return json.data
    return {}
```

### Task 3: Create ProfanityFilter (build-time tool)

**File:** `scripts/tools/profanity_filter.gd` (NEW)

This is an editor/build-time tool, not a runtime system. It validates content before bundling.

```gdscript
class_name ProfanityFilter
extends RefCounted

var _profanity_list: PackedStringArray = []
var _safe_words: PackedStringArray = []

func load_filter(json_path: String) -> void:
    var file := FileAccess.open(json_path, FileAccess.READ)
    if file == null:
        return
    var json := JSON.new()
    json.parse(file.get_as_text())
    file.close()
    var data: Dictionary = json.data
    _profanity_list = PackedStringArray(data.get("profanity", []))
    _safe_words = PackedStringArray(data.get("safe_words", []))

func check_word(word: String) -> bool:
    var lower := word.to_lower()
    if _safe_words.has(lower):
        return false  # Safe
    if _profanity_list.has(lower):
        return true  # Profane
    for profane in _profanity_list:
        if lower.contains(profane):
            if not _is_safe_context(lower, profane):
                return true
    return false

func check_compound(word_a: String, word_b: String) -> bool:
    return check_word(word_a) or check_word(word_b) or check_word(word_a + word_b)

func _is_safe_context(text: String, profane: String) -> bool:
    for safe in _safe_words:
        if safe.contains(profane) and text.contains(safe):
            return true
    return false
```

### Task 4: Create WordValidator (build-time tool)

**File:** `scripts/tools/word_validator.gd` (NEW)

Validates word pairs against a bundled dictionary file (simple word list).

```gdscript
class_name WordValidator
extends RefCounted

var _dictionary: Dictionary = {}  # word -> true (hash set pattern)
var _profanity_filter: ProfanityFilter

func load_dictionary(path: String) -> void:
    var file := FileAccess.open(path, FileAccess.READ)
    if file == null:
        push_warning("WordValidator: Could not load dictionary at " + path)
        return
    while not file.eof_reached():
        var word := file.get_line().strip_edges().to_lower()
        if word.length() > 0:
            _dictionary[word] = true
    file.close()

func set_profanity_filter(pf: ProfanityFilter) -> void:
    _profanity_filter = pf

func is_valid_word(word: String) -> bool:
    return _dictionary.has(word.to_lower())

func validate_pair(word_a: String, word_b: String) -> Dictionary:
    var result := {"valid": true, "errors": []}

    # Skip starter word (word_a empty)
    if word_a != "" and not is_valid_word(word_a):
        result.valid = false
        result.errors.append("Not in dictionary: " + word_a)

    if not is_valid_word(word_b):
        result.valid = false
        result.errors.append("Not in dictionary: " + word_b)

    if _profanity_filter and _profanity_filter.check_compound(word_a, word_b):
        result.valid = false
        result.errors.append("Profanity detected in: " + word_a + " + " + word_b)

    return result

func validate_level(word_pairs: Array) -> Dictionary:
    var results := {"valid_count": 0, "invalid_count": 0, "errors": []}
    for pair in word_pairs:
        var v := validate_pair(pair.get("word_a", ""), pair.get("word_b", ""))
        if v.valid:
            results.valid_count += 1
        else:
            results.invalid_count += 1
            results.errors.append_array(v.errors)
    return results
```

### Task 5: Create profanity filter data file

**File:** `data/filters/profanity_v1.json` (NEW)

Starter filter with common profanity terms and safe word exceptions. This will be expanded over time.

```json
{
  "version": "1.0.0",
  "profanity": ["<curated list>"],
  "safe_words": ["class", "assassin", "basement", "therapist", "assume", "grape", "scrap", "cocktail", "classic"]
}
```

Note: Actual profanity list will be populated from a curated source. Safe words prevent false positives on common English words that contain profane substrings.

### Task 6: Create baseline content -- Grasslands land (10 levels)

**File:** `data/baseline/grasslands.json` (NEW)

10 levels of nature-themed compound word pairs. Each level has 16 word pairs (1 starter + 12 base + 3 bonus), surge config, and obstacle configs for later levels.

Levels 1-3: No obstacles (tutorial levels)
Levels 4-5: Padlock obstacle
Levels 6-7: Random Blocks obstacle
Levels 8-10: Mixed obstacles

Word pairs follow compound word chains (snow->ball->park->etc pattern).

### Task 7: Register ContentCache autoload in project.godot

**File:** `project.godot` (EDIT)

Add ContentCache autoload after existing autoloads:
```
ContentCache="*res://scripts/autoloads/content_cache.gd"
```

### Task 8: Update GameplayScreen to load from ContentCache

**File:** `scripts/screens/gameplay_screen.gd` (EDIT)

Replace the hardcoded `load("res://data/levels/test_level_01.tres")` with ContentCache:

```gdscript
# In _ready() or a new setup_from_content() function:
var level_json := ContentCache.get_level_json("grasslands", 0)
_level_data = ContentCache.build_level_data(level_json)
```

Keep the .tres fallback for now:
```gdscript
if level_json.is_empty():
    _level_data = load("res://data/levels/test_level_01.tres")
else:
    _level_data = ContentCache.build_level_data(level_json)
```

### Task 9: Add content EventBus signals

**File:** `scripts/autoloads/event_bus.gd` (EDIT)

Add after obstacle signals:
```gdscript
# --- Content pipeline signals ---
signal content_update_available(version: String)
signal content_downloaded(land_id: String)
signal content_download_failed(land_id: String)
```

These signals are stubs for Phase 7 (cloud integration). ContentCache will emit them when the cloud download system is wired in.

---

## Verification

1. Delete user cache (`user://content_cache/`) -- game loads from `res://data/baseline/grasslands.json` fallback
2. Level 1 loads with correct word pairs, surge config, no obstacles
3. Level 5 loads with a padlock obstacle from JSON
4. Level 8 loads with mixed obstacles from JSON
5. ProfanityFilter correctly flags known profane compounds and allows safe words
6. WordValidator reports invalid words not in dictionary
7. The existing test_level_01.tres still works as fallback when JSON is empty
